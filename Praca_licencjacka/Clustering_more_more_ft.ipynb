{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wkaco\\AppData\\Local\\Temp\\ipykernel_11432\\2059561984.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pd.read_excel(\"C:/Users/wkaco/Desktop/Assets_data.xlsx\")\n",
    "macro_data = pd.read_excel(\"C:/Users/wkaco/Desktop/CPIGDP.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Prepare data\\nmacro_data, numeric_features, categorical_features = prepare_macro_data(macro_data)\\n\\n# Fit GMM with optimal number of clusters (e.g., 3)\\ngmm_model, cluster_labels, scaler = fit_optimal_gmm(macro_data[numeric_features], 3)\\n\\n# Create visualizations and analysis\\nplot_gmm_analysis(macro_data, X, cluster_labels, gmm_model, scaler)\\ncluster_stats, combined_data = analyze_gmm_clusters(macro_data, X, gmm_model, cluster_labels, scaler)\\ncluster_summary = create_cluster_summary(macro_data, cluster_labels)\\n\\n# Print results\\nprint(\"\\nCluster Summary:\")\\nprint(cluster_summary)\\nprint(\"\\nCluster Statistics:\")\\nprint(cluster_stats)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_macro_data(df):\n",
    "    \"\"\"\n",
    "    Prepare macro data by ensuring correct types and handling categorical variables.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Raw macro data\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Processed macro data with correct types\n",
    "    list: Numeric feature names\n",
    "    list: Categorical feature names\n",
    "    \"\"\"\n",
    "    # Define expected features and their types\n",
    "    numeric_features = [\n",
    "        'GDP', 'Inflation', 'Unemployment', 'Debt_Change', \n",
    "        'Credit_Spread', 'M2', '2y10y', '10y30y', \n",
    "        'Duration_Premium', '3m30y', 'Banking_Reserves', \n",
    "        'Feds_Total_Assets'\n",
    "    ]\n",
    "    \n",
    "    categorical_features = ['Yield_Curve_Regime']\n",
    "    \n",
    "    # Ensure all numeric features are float type\n",
    "    for feature in numeric_features:\n",
    "        if feature in df.columns:\n",
    "            df[feature] = pd.to_numeric(df[feature], errors='coerce')\n",
    "    \n",
    "    # Ensure categorical features are string type\n",
    "    for feature in categorical_features:\n",
    "        if feature in df.columns:\n",
    "            df[feature] = df[feature].astype(str)\n",
    "    \n",
    "    return df, numeric_features, categorical_features\n",
    "\n",
    "def plot_gmm_analysis(macro_data, X, cluster_labels, gmm_model, scaler):\n",
    "    \"\"\"Create comprehensive visualizations for GMM clustering analysis using matplotlib.\"\"\"\n",
    "    # Prepare data\n",
    "    macro_data, numeric_features, categorical_features = prepare_macro_data(macro_data)\n",
    "    \n",
    "    # Create figure with multiple subplots\n",
    "    fig = plt.figure(figsize=(20, 35))  # Increased height for additional features\n",
    "    gs = GridSpec(8, 2, figure=fig)  # Increased number of rows\n",
    "    \n",
    "    # 1. Plot first two principal components of macro features\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(scaler.transform(macro_data[numeric_features]))\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    scatter = ax1.scatter(pca_result[:, 0], pca_result[:, 1], \n",
    "                         c=cluster_labels + 1, \n",
    "                         cmap='viridis', \n",
    "                         s=100)\n",
    "    ax1.set_xlabel('First Principal Component', fontsize=12)\n",
    "    ax1.set_ylabel('Second Principal Component', fontsize=12)\n",
    "    ax1.set_title('Economic Regimes: PCA Visualization', fontsize=14)\n",
    "    ax1.grid(True)\n",
    "    plt.colorbar(scatter, ax=ax1, label='Cluster')\n",
    "    \n",
    "    # 2. Plot clusters over time\n",
    "    ax2 = fig.add_subplot(gs[1, :])\n",
    "    ax2.plot(macro_data.index, cluster_labels + 1, 'o-', linewidth=2)\n",
    "    ax2.set_xlabel('Date', fontsize=12)\n",
    "    ax2.set_ylabel('Cluster', fontsize=12)\n",
    "    ax2.set_title('Economic Regime Evolution Over Time', fontsize=14)\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # 3. Plot mean macro features by cluster\n",
    "    cluster_stats = pd.DataFrame()\n",
    "    for cluster in range(len(np.unique(cluster_labels))):\n",
    "        mask = cluster_labels == cluster\n",
    "        cluster_stats[f'Cluster {cluster+1}'] = macro_data.loc[mask, numeric_features].mean()\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[2, :])\n",
    "    cluster_stats.T.plot(kind='bar', ax=ax3)\n",
    "    ax3.set_title('Mean Macro Features by Cluster', fontsize=14)\n",
    "    ax3.set_xlabel('Cluster', fontsize=12)\n",
    "    ax3.set_ylabel('Value', fontsize=12)\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # 4. Plot feature correlations within clusters\n",
    "    for i, cluster in enumerate(range(len(np.unique(cluster_labels)))):\n",
    "        ax = fig.add_subplot(gs[3+i, :])\n",
    "        mask = cluster_labels == cluster\n",
    "        corr_matrix = macro_data.loc[mask, numeric_features].corr()\n",
    "        \n",
    "        im = ax.imshow(corr_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
    "        plt.colorbar(im, ax=ax)\n",
    "        \n",
    "        ax.set_xticks(np.arange(len(numeric_features)))\n",
    "        ax.set_yticks(np.arange(len(numeric_features)))\n",
    "        ax.set_xticklabels(numeric_features, rotation=45, ha='right')\n",
    "        ax.set_yticklabels(numeric_features)\n",
    "        \n",
    "        for i in range(len(numeric_features)):\n",
    "            for j in range(len(numeric_features)):\n",
    "                text = ax.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
    "                             ha=\"center\", va=\"center\", color=\"black\")\n",
    "        \n",
    "        ax.set_title(f'Feature Correlations - Cluster {cluster+1}', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 5. Feature distributions by cluster\n",
    "    plot_feature_distributions(macro_data, numeric_features, cluster_labels)\n",
    "    \n",
    "    # 6. New: Yield Curve Regime analysis by cluster\n",
    "    plot_regime_analysis(macro_data, cluster_labels)\n",
    "\n",
    "def plot_feature_distributions(macro_data, numeric_features, cluster_labels):\n",
    "    \"\"\"Plot distributions for all numeric features by cluster.\"\"\"\n",
    "    n_features = len(numeric_features)\n",
    "    n_clusters = len(np.unique(cluster_labels))\n",
    "    \n",
    "    fig, axes = plt.subplots(n_features, 1, figsize=(15, 5*n_features))\n",
    "    fig.suptitle('Feature Distributions by Cluster', fontsize=16)\n",
    "    \n",
    "    for idx, feature in enumerate(numeric_features):\n",
    "        ax = axes[idx]\n",
    "        for cluster in range(n_clusters):\n",
    "            mask = cluster_labels == cluster\n",
    "            feature_data = macro_data.loc[mask, feature]\n",
    "            ax.hist(feature_data, bins=20, alpha=0.5, \n",
    "                   label=f'Cluster {cluster+1}', density=True)\n",
    "        ax.set_title(f'{feature} Distribution')\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_regime_analysis(macro_data, cluster_labels):\n",
    "    \"\"\"Plot analysis of Yield Curve Regime distribution within each cluster.\"\"\"\n",
    "    n_clusters = len(np.unique(cluster_labels))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    regime_counts = []\n",
    "    for cluster in range(n_clusters):\n",
    "        mask = cluster_labels == cluster\n",
    "        regime_dist = macro_data.loc[mask, 'Yield_Curve_Regime'].value_counts()\n",
    "        regime_counts.append(regime_dist)\n",
    "    \n",
    "    regime_df = pd.DataFrame(regime_counts).fillna(0)\n",
    "    regime_df.plot(kind='bar', ax=ax)\n",
    "    \n",
    "    ax.set_title('Yield Curve Regime Distribution by Cluster', fontsize=14)\n",
    "    ax.set_xlabel('Cluster')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend(title='Regime', bbox_to_anchor=(1.05, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_cluster_summary(macro_data, cluster_labels):\n",
    "    \"\"\"Create a comprehensive summary of each cluster's characteristics.\"\"\"\n",
    "    macro_data, numeric_features, categorical_features = prepare_macro_data(macro_data)\n",
    "    summary = pd.DataFrame()\n",
    "    \n",
    "    for cluster in range(len(np.unique(cluster_labels))):\n",
    "        mask = cluster_labels == cluster\n",
    "        cluster_data = macro_data.loc[mask]\n",
    "        \n",
    "        # Numeric features summary\n",
    "        stats = {}\n",
    "        for feature in numeric_features:\n",
    "            stats.update({\n",
    "                f'{feature}_Mean': cluster_data[feature].mean(),\n",
    "                f'{feature}_Std': cluster_data[feature].std(),\n",
    "                f'{feature}_Min': cluster_data[feature].min(),\n",
    "                f'{feature}_Max': cluster_data[feature].max()\n",
    "            })\n",
    "        \n",
    "        # Categorical features summary\n",
    "        for feature in categorical_features:\n",
    "            mode_value = cluster_data[feature].mode().iloc[0]\n",
    "            mode_freq = (cluster_data[feature] == mode_value).mean()\n",
    "            stats.update({\n",
    "                f'{feature}_Mode': mode_value,\n",
    "                f'{feature}_Mode_Freq': mode_freq\n",
    "            })\n",
    "        \n",
    "        summary[f'Cluster_{cluster+1}'] = pd.Series(stats)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def analyze_gmm_clusters(macro_data, asset_returns, gmm_model, cluster_labels, scaler):\n",
    "    \"\"\"Analyze asset returns across different GMM clusters.\"\"\"\n",
    "    macro_data, numeric_features, _ = prepare_macro_data(macro_data)\n",
    "    \n",
    "    # Add cluster labels\n",
    "    macro_data = macro_data.copy()\n",
    "    macro_data['Cluster'] = cluster_labels\n",
    "    \n",
    "    # Ensure dates are datetime\n",
    "    macro_data.index = pd.to_datetime(macro_data.index)\n",
    "    asset_returns.index = pd.to_datetime(asset_returns.index)\n",
    "    \n",
    "    # Merge data\n",
    "    combined_data = asset_returns.merge(\n",
    "        macro_data,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Calculate statistics\n",
    "    cluster_stats = pd.DataFrame()\n",
    "    \n",
    "    for cluster in range(gmm_model.n_components):\n",
    "        cluster_data = combined_data[combined_data['Cluster'] == cluster]\n",
    "        \n",
    "        # Asset returns statistics\n",
    "        mean_returns = cluster_data[asset_returns.columns].mean()\n",
    "        volatility = cluster_data[asset_returns.columns].std()\n",
    "        sharpe = mean_returns / volatility\n",
    "        macro_means = cluster_data[numeric_features].mean()\n",
    "        \n",
    "        # Store results\n",
    "        cluster_stats[f'Cluster_{cluster+1}_Mean'] = mean_returns\n",
    "        cluster_stats[f'Cluster_{cluster+1}_Vol'] = volatility\n",
    "        cluster_stats[f'Cluster_{cluster+1}_Sharpe'] = sharpe\n",
    "        for feature in numeric_features:\n",
    "            cluster_stats.loc[feature, f'Cluster_{cluster+1}_Mean'] = macro_means[feature]\n",
    "    \n",
    "    return cluster_stats, combined_data\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "# Prepare data\n",
    "macro_data, numeric_features, categorical_features = prepare_macro_data(macro_data)\n",
    "\n",
    "# Fit GMM with optimal number of clusters (e.g., 3)\n",
    "gmm_model, cluster_labels, scaler = fit_optimal_gmm(macro_data[numeric_features], 3)\n",
    "\n",
    "# Create visualizations and analysis\n",
    "plot_gmm_analysis(macro_data, X, cluster_labels, gmm_model, scaler)\n",
    "cluster_stats, combined_data = analyze_gmm_clusters(macro_data, X, gmm_model, cluster_labels, scaler)\n",
    "cluster_summary = create_cluster_summary(macro_data, cluster_labels)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nCluster Summary:\")\n",
    "print(cluster_summary)\n",
    "print(\"\\nCluster Statistics:\")\n",
    "print(cluster_stats)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_data, numeric_features, categorical_features = prepare_macro_data(macro_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = macro_data.select_dtypes(include=[np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyze_clustering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43manalyze_clustering\u001b[49m(macro_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'analyze_clustering' is not defined"
     ]
    }
   ],
   "source": [
    "analyze_clustering(macro_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_optimal_gmm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m macro_data, numeric_features, categorical_features \u001b[38;5;241m=\u001b[39m prepare_macro_data(macro_data)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fit GMM\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m gmm_model, cluster_labels, scaler \u001b[38;5;241m=\u001b[39m \u001b[43mfit_optimal_gmm\u001b[49m(macro_data[numeric_features], \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create visualizations and analysis\u001b[39;00m\n\u001b[0;32m      8\u001b[0m plot_gmm_analysis(macro_data, X, cluster_labels, gmm_model, scaler)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit_optimal_gmm' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
